<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
    "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8" />
<meta name="generator" content="AsciiDoc 8.6.10" />
<title>Parallel GNU APL</title>
<style type="text/css">
/* Shared CSS for AsciiDoc xhtml11 and html5 backends */

/* Default font. */
body {
  font-family: Georgia,serif;
}

/* Title font. */
h1, h2, h3, h4, h5, h6,
div.title, caption.title,
thead, p.table.header,
#toctitle,
#author, #revnumber, #revdate, #revremark,
#footer {
  font-family: Arial,Helvetica,sans-serif;
}

body {
  margin: 1em 5% 1em 5%;
}

a {
  color: blue;
  text-decoration: underline;
}
a:visited {
  color: fuchsia;
}

em {
  font-style: italic;
  color: navy;
}

strong {
  font-weight: bold;
  color: #083194;
}

h1, h2, h3, h4, h5, h6 {
  color: #527bbd;
  margin-top: 1.2em;
  margin-bottom: 0.5em;
  line-height: 1.3;
}

h1, h2, h3 {
  border-bottom: 2px solid silver;
}
h2 {
  padding-top: 0.5em;
}
h3 {
  float: left;
}
h3 + * {
  clear: left;
}
h5 {
  font-size: 1.0em;
}

div.sectionbody {
  margin-left: 0;
}

hr {
  border: 1px solid silver;
}

p {
  margin-top: 0.5em;
  margin-bottom: 0.5em;
}

ul, ol, li > p {
  margin-top: 0;
}
ul > li     { color: #aaa; }
ul > li > * { color: black; }

.monospaced, code, pre {
  font-family: "Courier New", Courier, monospace;
  font-size: inherit;
  color: navy;
  padding: 0;
  margin: 0;
}
pre {
  white-space: pre-wrap;
}

#author {
  color: #527bbd;
  font-weight: bold;
  font-size: 1.1em;
}
#email {
}
#revnumber, #revdate, #revremark {
}

#footer {
  font-size: small;
  border-top: 2px solid silver;
  padding-top: 0.5em;
  margin-top: 4.0em;
}
#footer-text {
  float: left;
  padding-bottom: 0.5em;
}
#footer-badges {
  float: right;
  padding-bottom: 0.5em;
}

#preamble {
  margin-top: 1.5em;
  margin-bottom: 1.5em;
}
div.imageblock, div.exampleblock, div.verseblock,
div.quoteblock, div.literalblock, div.listingblock, div.sidebarblock,
div.admonitionblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
div.admonitionblock {
  margin-top: 2.0em;
  margin-bottom: 2.0em;
  margin-right: 10%;
  color: #606060;
}

div.content { /* Block element content. */
  padding: 0;
}

/* Block element titles. */
div.title, caption.title {
  color: #527bbd;
  font-weight: bold;
  text-align: left;
  margin-top: 1.0em;
  margin-bottom: 0.5em;
}
div.title + * {
  margin-top: 0;
}

td div.title:first-child {
  margin-top: 0.0em;
}
div.content div.title:first-child {
  margin-top: 0.0em;
}
div.content + div.title {
  margin-top: 0.0em;
}

div.sidebarblock > div.content {
  background: #ffffee;
  border: 1px solid #dddddd;
  border-left: 4px solid #f0f0f0;
  padding: 0.5em;
}

div.listingblock > div.content {
  border: 1px solid #dddddd;
  border-left: 5px solid #f0f0f0;
  background: #f8f8f8;
  padding: 0.5em;
}

div.quoteblock, div.verseblock {
  padding-left: 1.0em;
  margin-left: 1.0em;
  margin-right: 10%;
  border-left: 5px solid #f0f0f0;
  color: #888;
}

div.quoteblock > div.attribution {
  padding-top: 0.5em;
  text-align: right;
}

div.verseblock > pre.content {
  font-family: inherit;
  font-size: inherit;
}
div.verseblock > div.attribution {
  padding-top: 0.75em;
  text-align: left;
}
/* DEPRECATED: Pre version 8.2.7 verse style literal block. */
div.verseblock + div.attribution {
  text-align: left;
}

div.admonitionblock .icon {
  vertical-align: top;
  font-size: 1.1em;
  font-weight: bold;
  text-decoration: underline;
  color: #527bbd;
  padding-right: 0.5em;
}
div.admonitionblock td.content {
  padding-left: 0.5em;
  border-left: 3px solid #dddddd;
}

div.exampleblock > div.content {
  border-left: 3px solid #dddddd;
  padding-left: 0.5em;
}

div.imageblock div.content { padding-left: 0; }
span.image img { border-style: none; vertical-align: text-bottom; }
a.image:visited { color: white; }

dl {
  margin-top: 0.8em;
  margin-bottom: 0.8em;
}
dt {
  margin-top: 0.5em;
  margin-bottom: 0;
  font-style: normal;
  color: navy;
}
dd > *:first-child {
  margin-top: 0.1em;
}

ul, ol {
    list-style-position: outside;
}
ol.arabic {
  list-style-type: decimal;
}
ol.loweralpha {
  list-style-type: lower-alpha;
}
ol.upperalpha {
  list-style-type: upper-alpha;
}
ol.lowerroman {
  list-style-type: lower-roman;
}
ol.upperroman {
  list-style-type: upper-roman;
}

div.compact ul, div.compact ol,
div.compact p, div.compact p,
div.compact div, div.compact div {
  margin-top: 0.1em;
  margin-bottom: 0.1em;
}

tfoot {
  font-weight: bold;
}
td > div.verse {
  white-space: pre;
}

div.hdlist {
  margin-top: 0.8em;
  margin-bottom: 0.8em;
}
div.hdlist tr {
  padding-bottom: 15px;
}
dt.hdlist1.strong, td.hdlist1.strong {
  font-weight: bold;
}
td.hdlist1 {
  vertical-align: top;
  font-style: normal;
  padding-right: 0.8em;
  color: navy;
}
td.hdlist2 {
  vertical-align: top;
}
div.hdlist.compact tr {
  margin: 0;
  padding-bottom: 0;
}

.comment {
  background: yellow;
}

.footnote, .footnoteref {
  font-size: 0.8em;
}

span.footnote, span.footnoteref {
  vertical-align: super;
}

#footnotes {
  margin: 20px 0 20px 0;
  padding: 7px 0 0 0;
}

#footnotes div.footnote {
  margin: 0 0 5px 0;
}

#footnotes hr {
  border: none;
  border-top: 1px solid silver;
  height: 1px;
  text-align: left;
  margin-left: 0;
  width: 20%;
  min-width: 100px;
}

div.colist td {
  padding-right: 0.5em;
  padding-bottom: 0.3em;
  vertical-align: top;
}
div.colist td img {
  margin-top: 0.3em;
}

@media print {
  #footer-badges { display: none; }
}

#toc {
  margin-bottom: 2.5em;
}

#toctitle {
  color: #527bbd;
  font-size: 1.1em;
  font-weight: bold;
  margin-top: 1.0em;
  margin-bottom: 0.1em;
}

div.toclevel0, div.toclevel1, div.toclevel2, div.toclevel3, div.toclevel4 {
  margin-top: 0;
  margin-bottom: 0;
}
div.toclevel2 {
  margin-left: 2em;
  font-size: 0.9em;
}
div.toclevel3 {
  margin-left: 4em;
  font-size: 0.9em;
}
div.toclevel4 {
  margin-left: 6em;
  font-size: 0.9em;
}

span.aqua { color: aqua; }
span.black { color: black; }
span.blue { color: blue; }
span.fuchsia { color: fuchsia; }
span.gray { color: gray; }
span.green { color: green; }
span.lime { color: lime; }
span.maroon { color: maroon; }
span.navy { color: navy; }
span.olive { color: olive; }
span.purple { color: purple; }
span.red { color: red; }
span.silver { color: silver; }
span.teal { color: teal; }
span.white { color: white; }
span.yellow { color: yellow; }

span.aqua-background { background: aqua; }
span.black-background { background: black; }
span.blue-background { background: blue; }
span.fuchsia-background { background: fuchsia; }
span.gray-background { background: gray; }
span.green-background { background: green; }
span.lime-background { background: lime; }
span.maroon-background { background: maroon; }
span.navy-background { background: navy; }
span.olive-background { background: olive; }
span.purple-background { background: purple; }
span.red-background { background: red; }
span.silver-background { background: silver; }
span.teal-background { background: teal; }
span.white-background { background: white; }
span.yellow-background { background: yellow; }

span.big { font-size: 2em; }
span.small { font-size: 0.6em; }

span.underline { text-decoration: underline; }
span.overline { text-decoration: overline; }
span.line-through { text-decoration: line-through; }

div.unbreakable { page-break-inside: avoid; }


/*
 * xhtml11 specific
 *
 * */

div.tableblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
div.tableblock > table {
  border: 3px solid #527bbd;
}
thead, p.table.header {
  font-weight: bold;
  color: #527bbd;
}
p.table {
  margin-top: 0;
}
/* Because the table frame attribute is overriden by CSS in most browsers. */
div.tableblock > table[frame="void"] {
  border-style: none;
}
div.tableblock > table[frame="hsides"] {
  border-left-style: none;
  border-right-style: none;
}
div.tableblock > table[frame="vsides"] {
  border-top-style: none;
  border-bottom-style: none;
}


/*
 * html5 specific
 *
 * */

table.tableblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
thead, p.tableblock.header {
  font-weight: bold;
  color: #527bbd;
}
p.tableblock {
  margin-top: 0;
}
table.tableblock {
  border-width: 3px;
  border-spacing: 0px;
  border-style: solid;
  border-color: #527bbd;
  border-collapse: collapse;
}
th.tableblock, td.tableblock {
  border-width: 1px;
  padding: 4px;
  border-style: solid;
  border-color: #527bbd;
}

table.tableblock.frame-topbot {
  border-left-style: hidden;
  border-right-style: hidden;
}
table.tableblock.frame-sides {
  border-top-style: hidden;
  border-bottom-style: hidden;
}
table.tableblock.frame-none {
  border-style: hidden;
}

th.tableblock.halign-left, td.tableblock.halign-left {
  text-align: left;
}
th.tableblock.halign-center, td.tableblock.halign-center {
  text-align: center;
}
th.tableblock.halign-right, td.tableblock.halign-right {
  text-align: right;
}

th.tableblock.valign-top, td.tableblock.valign-top {
  vertical-align: top;
}
th.tableblock.valign-middle, td.tableblock.valign-middle {
  vertical-align: middle;
}
th.tableblock.valign-bottom, td.tableblock.valign-bottom {
  vertical-align: bottom;
}


/*
 * manpage specific
 *
 * */

body.manpage h1 {
  padding-top: 0.5em;
  padding-bottom: 0.5em;
  border-top: 2px solid silver;
  border-bottom: 2px solid silver;
}
body.manpage h2 {
  border-style: none;
}
body.manpage div.sectionbody {
  margin-left: 3em;
}

@media print {
  body.manpage div#toc { display: none; }
}


</style>
<script type="text/javascript">
/*<![CDATA[*/
var asciidoc = {  // Namespace.

/////////////////////////////////////////////////////////////////////
// Table Of Contents generator
/////////////////////////////////////////////////////////////////////

/* Author: Mihai Bazon, September 2002
 * http://students.infoiasi.ro/~mishoo
 *
 * Table Of Content generator
 * Version: 0.4
 *
 * Feel free to use this script under the terms of the GNU General Public
 * License, as long as you do not remove or alter this notice.
 */

 /* modified by Troy D. Hanson, September 2006. License: GPL */
 /* modified by Stuart Rackham, 2006, 2009. License: GPL */

// toclevels = 1..4.
toc: function (toclevels) {

  function getText(el) {
    var text = "";
    for (var i = el.firstChild; i != null; i = i.nextSibling) {
      if (i.nodeType == 3 /* Node.TEXT_NODE */) // IE doesn't speak constants.
        text += i.data;
      else if (i.firstChild != null)
        text += getText(i);
    }
    return text;
  }

  function TocEntry(el, text, toclevel) {
    this.element = el;
    this.text = text;
    this.toclevel = toclevel;
  }

  function tocEntries(el, toclevels) {
    var result = new Array;
    var re = new RegExp('[hH]([1-'+(toclevels+1)+'])');
    // Function that scans the DOM tree for header elements (the DOM2
    // nodeIterator API would be a better technique but not supported by all
    // browsers).
    var iterate = function (el) {
      for (var i = el.firstChild; i != null; i = i.nextSibling) {
        if (i.nodeType == 1 /* Node.ELEMENT_NODE */) {
          var mo = re.exec(i.tagName);
          if (mo && (i.getAttribute("class") || i.getAttribute("className")) != "float") {
            result[result.length] = new TocEntry(i, getText(i), mo[1]-1);
          }
          iterate(i);
        }
      }
    }
    iterate(el);
    return result;
  }

  var toc = document.getElementById("toc");
  if (!toc) {
    return;
  }

  // Delete existing TOC entries in case we're reloading the TOC.
  var tocEntriesToRemove = [];
  var i;
  for (i = 0; i < toc.childNodes.length; i++) {
    var entry = toc.childNodes[i];
    if (entry.nodeName.toLowerCase() == 'div'
     && entry.getAttribute("class")
     && entry.getAttribute("class").match(/^toclevel/))
      tocEntriesToRemove.push(entry);
  }
  for (i = 0; i < tocEntriesToRemove.length; i++) {
    toc.removeChild(tocEntriesToRemove[i]);
  }

  // Rebuild TOC entries.
  var entries = tocEntries(document.getElementById("content"), toclevels);
  for (var i = 0; i < entries.length; ++i) {
    var entry = entries[i];
    if (entry.element.id == "")
      entry.element.id = "_toc_" + i;
    var a = document.createElement("a");
    a.href = "#" + entry.element.id;
    a.appendChild(document.createTextNode(entry.text));
    var div = document.createElement("div");
    div.appendChild(a);
    div.className = "toclevel" + entry.toclevel;
    toc.appendChild(div);
  }
  if (entries.length == 0)
    toc.parentNode.removeChild(toc);
},


/////////////////////////////////////////////////////////////////////
// Footnotes generator
/////////////////////////////////////////////////////////////////////

/* Based on footnote generation code from:
 * http://www.brandspankingnew.net/archive/2005/07/format_footnote.html
 */

footnotes: function () {
  // Delete existing footnote entries in case we're reloading the footnodes.
  var i;
  var noteholder = document.getElementById("footnotes");
  if (!noteholder) {
    return;
  }
  var entriesToRemove = [];
  for (i = 0; i < noteholder.childNodes.length; i++) {
    var entry = noteholder.childNodes[i];
    if (entry.nodeName.toLowerCase() == 'div' && entry.getAttribute("class") == "footnote")
      entriesToRemove.push(entry);
  }
  for (i = 0; i < entriesToRemove.length; i++) {
    noteholder.removeChild(entriesToRemove[i]);
  }

  // Rebuild footnote entries.
  var cont = document.getElementById("content");
  var spans = cont.getElementsByTagName("span");
  var refs = {};
  var n = 0;
  for (i=0; i<spans.length; i++) {
    if (spans[i].className == "footnote") {
      n++;
      var note = spans[i].getAttribute("data-note");
      if (!note) {
        // Use [\s\S] in place of . so multi-line matches work.
        // Because JavaScript has no s (dotall) regex flag.
        note = spans[i].innerHTML.match(/\s*\[([\s\S]*)]\s*/)[1];
        spans[i].innerHTML =
          "[<a id='_footnoteref_" + n + "' href='#_footnote_" + n +
          "' title='View footnote' class='footnote'>" + n + "</a>]";
        spans[i].setAttribute("data-note", note);
      }
      noteholder.innerHTML +=
        "<div class='footnote' id='_footnote_" + n + "'>" +
        "<a href='#_footnoteref_" + n + "' title='Return to text'>" +
        n + "</a>. " + note + "</div>";
      var id =spans[i].getAttribute("id");
      if (id != null) refs["#"+id] = n;
    }
  }
  if (n == 0)
    noteholder.parentNode.removeChild(noteholder);
  else {
    // Process footnoterefs.
    for (i=0; i<spans.length; i++) {
      if (spans[i].className == "footnoteref") {
        var href = spans[i].getElementsByTagName("a")[0].getAttribute("href");
        href = href.match(/#.*/)[0];  // Because IE return full URL.
        n = refs[href];
        spans[i].innerHTML =
          "[<a href='#_footnote_" + n +
          "' title='View footnote' class='footnote'>" + n + "</a>]";
      }
    }
  }
},

install: function(toclevels) {
  var timerId;

  function reinstall() {
    asciidoc.footnotes();
    if (toclevels) {
      asciidoc.toc(toclevels);
    }
  }

  function reinstallAndRemoveTimer() {
    clearInterval(timerId);
    reinstall();
  }

  timerId = setInterval(reinstall, 500);
  if (document.addEventListener)
    document.addEventListener("DOMContentLoaded", reinstallAndRemoveTimer, false);
  else
    window.onload = reinstallAndRemoveTimer;
}

}
asciidoc.install(4);
/*]]>*/
</script>
</head>
<body class="article">
<div id="header">
<h1>Parallel GNU APL</h1>
<span id="author">Jürgen Sauermann, GNU APL</span><br />
<div id="toc">
  <div id="toctitle">Table of Contents</div>
  <noscript><p><b>JavaScript must be enabled in your browser to display the table of contents.</b></p></noscript>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_abstract">Abstract</h2>
<div class="sectionbody">
<div class="paragraph"><p>This document briefly describes parallel execution in GNU APL</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_configuration">Configuration</h2>
<div class="sectionbody">
<div class="paragraph"><p>Parallel execution of APL primitives needs to be <strong>./configure</strong>'d explicitly.
Without such configuration GNU APL executes sequentially. In freshly installed
GNU APL sources (i.e. after a SVN checkout or after unpacking the GNU APL tar
file), the configuration is:</p></div>
<div class="listingblock">
<div class="content">
<pre>

<code>./configure --enable-maintainer-mode            \
            VALUE_CHECK_WANTED=no               \
            VALUE_HISTORY_WANTED=no             \
            PERFORMANCE_COUNTERS_WANTED=yes     \
            DYNAMIC_LOG_WANTED=yes              \
            ASSERT_LEVEL_WANTED=0               \
            CORE_COUNT_WANTED=-3</code>

</pre>
</div></div>
<div class="paragraph"><p>If the sources were already ./configure&#8217;d then two make targets achieve
the same:</p></div>
<div class="listingblock">
<div class="content">
<pre>

<code>make parallel
make parallel1</code>

</pre>
</div></div>
<div class="paragraph"><p>The first make target <strong>parallel</strong> is the setting for maximum performance, while
the second make target <strong>parallel1</strong> is like <strong>parallel</strong> but with internal
performance counters enabled. The performance counters are needed for
benchmarking of the GNU APL performance via <strong>FIO∆get_statistics</strong> in workspace
<strong>5 FILE_IO</strong> resp. <strong>⎕FIO[201]</strong>.</p></div>
<div class="admonitionblock">
<table><tr>
<td class="icon">
<img src="/usr/share/asciidoc/icons/caution.png" alt="Caution" />
</td>
<td class="content">Parallel execution is a fully experimental feature that should not
be used in mission-critical applications. Support for bugs caused by
this feature is rather limited.</td>
</tr></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_controlling_the_core_count">Controlling the Core Count</h2>
<div class="sectionbody">
<div class="paragraph"><p>The number of cores that are used by the parallel APL execution can be
controlled in several ways.</p></div>
<div class="sect2">
<h3 id="_the_configure_option_core_count_wanted">The ./configure Option CORE_COUNT_WANTED</h3>
<div class="paragraph"><p>The first way to control the (maximum) core count at the point time when the
interpreter source code is being ./configure&#8217;d. The configure option
CORE_COUNT_WANTED defines how the interpreter chooses the number of cores
(see <strong>README-2-configure</strong>):</p></div>
<div class="ulist"><ul>
<li>
<p>
CORE_COUNT_WANTED=0: sequential
</p>
</li>
<li>
<p>
CORE_COUNT_WANTED=1: parallel (but using only 1 core)
</p>
</li>
<li>
<p>
CORE_COUNT_WANTED=2: parallel on 2 cores
</p>
</li>
<li>
<p>
&#8230;
</p>
</li>
<li>
<p>
CORE_COUNT_WANTED=N: parallel on N cores
</p>
</li>
<li>
<p>
CORE_COUNT_WANTED=-1: parallel on all existing cores
</p>
</li>
<li>
<p>
CORE_COUNT_WANTED=-2: parallel; the core count is determined by the command
  line argument -cc of the interpreter
</p>
</li>
<li>
<p>
CORE_COUNT_WANTED=-3: parallel; the core count is determined at interpreter
  run-time via ⎕SYL;
</p>
</li>
</ul></div>
<div class="admonitionblock">
<table><tr>
<td class="icon">
<img src="/usr/share/asciidoc/icons/note.png" alt="Note" />
</td>
<td class="content">The command line option -cc works only if CORE_COUNT_WANTED=-2. For
CORE_COUNT_WANTED &gt; 1 or -2, it is the responsibility of the user to ensure
that the desired number of cores actually exist (i.e. this is not checked
because some platforms cannot do that).</td>
</tr></table>
</div>
<div class="paragraph"><p><strong>CORE_COUNT_WANTED=-3</strong> is the most useful setting, because it allows to change
the core count at run-time of an APL program (e.g. in a benchmarking workspace
like <strong>Scalar2.apl</strong>).</p></div>
</div>
<div class="sect2">
<h3 id="_changing_the_core_count_at_run_time">Changing the Core Count at Run-time</h3>
<div class="paragraph"><p>If <strong>CORE_COUNT_WANTED=-3</strong> (the default) then the system variable <strong>⎕SYL</strong>, in
particular <strong>⎕SYL[25 26 27;]</strong> control the number of cores being used:</p></div>
<div class="listingblock">
<div class="content">
<pre>

<code>      ⎕SYL[24 25 26;]
 CORE_COUNT_WANTED (per ./configure) ¯3
 cores available                     12
 cores used                           1</code>

</pre>
</div></div>
<div class="sect3">
<h4 id="_syl_24_2">⎕SYL[24;2]</h4>
<div class="paragraph"><p><strong>⎕SYL[24;2])</strong> is a read-only value pertaining to the value used for
<strong>CORE_COUNT_WANTED</strong> in <strong>./configure</strong>.</p></div>
</div>
<div class="sect3">
<h4 id="_syl_25_2">⎕SYL[25;2]</h4>
<div class="paragraph"><p><strong>⎕SYL[25;2])</strong> is the number of cores either chosen by ⎕SYL[24;2] or else as
indicated by the platform. The value 12 above as reported on a i7-8700
Intel CPU with 6 physical cores and 2 core threads per physical core.</p></div>
</div>
<div class="sect3">
<h4 id="_syl_26_2">⎕SYL[26;2]</h4>
<div class="paragraph"><p><strong>⎕SYL[26;2])</strong> is the number of cores used by the interpreter. Setting:</p></div>
<div class="paragraph"><p><strong>⎕SYL[26;2])←0</strong> chooses sequential operation of the interpreter.
<strong>⎕SYL[26;2])←N</strong> with <strong>N≥1 chooses parallel operation on *N</strong> cores.
* Other values trigger a <strong>DOMAIN ERROR</strong>.</p></div>
<div class="admonitionblock">
<table><tr>
<td class="icon">
<img src="/usr/share/asciidoc/icons/note.png" alt="Note" />
</td>
<td class="content"><strong>⎕SYL[26;2])←1</strong> could be useful for benchmarking to see the difference
between parallel and sequential code, but without distributing the
computational load over several cores.</td>
</tr></table>
</div>
<div class="paragraph"><p>Setting <strong>⎕SYL[26;2]</strong> with a proper value in APL calls
<strong>Parallel::set_core_count()</strong> in <strong>Parallel:cc</strong>.</p></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_initialization_of_the_parallel_subsystem">The Initialization of the Parallel Subsystem</h2>
<div class="sectionbody">
<div class="paragraph"><p>The parallel execution is initialized as follows.</p></div>
<div class="ulist"><ul>
<li>
<p>
the initialization is performed automatically when the interpreter is
  started (function <strong>Parallel::init()</strong>). If the interpreter is ./configured
  with <strong>DYNAMIC_LOG_WANTED=yes</strong> then logging of the initialization can be
  enabled with command line option <strong>-l 41</strong>.
</p>
</li>
<li>
<p>
<strong>Parallel::init()</strong> initializes semaphores related to the parallel execution
  and then calls <strong>CPU_pool::init()</strong>. <strong>CPU_pool::init()</strong> determines, which CPUs
   can be used by the interpreter and stores them in its vector <strong>the_CPUs</strong>.
   If <strong>CORE_COUNT_WANTED</strong> is <strong>≥ 0</strong> or <strong>-2</strong> then the CPUs in the vector are
   determined by <strong>CORE_COUNT_WANTED</strong> or by the <strong>-cc</strong> command line option (and
   no checks are performed in order to check if the CPUs chosen are
   correct). Otherwise, i.e.  (<strong>CORE_COUNT_WANTED</strong> is -1 or -3) the cores
   available to the interpreter are determined by <strong>pthread_getaffinity_np()</strong>
   and all CPUs that are available to the interpreter are stored in the vector.
</p>
</li>
<li>
<p>
Then <strong>Parallel::init()</strong> creates a thread pool with
  <strong>Thread_context::init_parallel</strong>, with one thread for each CPU
  in <strong>CPU_pool::the_CPUs</strong>. If <strong>CORE_COUNT_WANTED = -3</strong> then only the first
  thread is activated (and the user needs to use ⎕SYL in order to activate
  more cores. Otherwise all threads are activated (and ⎕SYL cannot be used).
  Finally <strong>Parallel::init()</strong> brings all threads into their initial state.
</p>
</li>
</ul></div>
<div class="paragraph"><p>At any point in time, a thread can be in one of 2 states:</p></div>
<div class="ulist"><ul>
<li>
<p>
BLKD: Blocked on its private semaphore <strong>Thread_context::pool_sema</strong>, or
</p>
</li>
<li>
<p>
RUN:  Running.
</p>
</li>
</ul></div>
<div class="paragraph"><p>A thread in state RUN can further be in 2 sub-states:</p></div>
<div class="ulist"><ul>
<li>
<p>
busy-waiting for more work to become available, or
</p>
</li>
<li>
<p>
computing the current job.
</p>
</li>
</ul></div>
<div class="paragraph"><p>The first thread in the pool, aka. the <strong>master</strong>, is always in state <strong>RUN</strong> and
is never busy-waiting (instead it executes the APL interpreter).</p></div>
<div class="paragraph"><p>The remaining threads, aka. the <strong>workers</strong>, are in state <strong>BLKD</strong> as long as
they are inactive (this can only happen if ⎕SYL is being used and the worker
is above the value set with ⎕SYL). Otherwise the worker is in state <strong>RUN</strong>. A
worker in state <strong>RUN</strong> is not necessarily computing, e.g. if the joblists are
empty and the worker is busy-waiting for more work.</p></div>
<div class="paragraph"><p>When the interpreter (i.e. the master) needs to compute a primitive scalar
function (or an inner or outer product of a primitive scalar function) with
sufficiently large argument, then it unleashes the workers
(<strong>Thread_context::M_fork()</strong>), performs its own share of the work, and waits
for all workers to complete their share of the work
(<strong>Thread_context::M_join()</strong>).</p></div>
<div class="paragraph"><p>At the same time, the workers wait for the master&#8217;s <strong>M_fork()</strong> in
<strong>Thread_context::PF_fork()</strong>, perform their share of the work, indicate that
 their work is complete, and wait for all others to complete as well
(<strong>Thread_context::M_join()</strong>).</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_the_operation_of_the_parallel_subsystem">The Operation of the Parallel Subsystem</h2>
<div class="sectionbody">
<div class="paragraph"><p>After initialization, the parallel subsystem works (see <strong>Thread_context.cc/hh</strong>) as
follows.</p></div>
<div class="ulist"><ul>
<li>
<p>
worker thread in state BLKD do nothing. This case can only occur with
  <strong>CORE_COUNT_WANTED=-3</strong>, and the transition between states BLKD and RUN can
  (after the initialization) only occur by setting ⎕SYL[26;2].
</p>
</li>
<li>
<p>
every thread maintains a variable <strong>job_number</strong> which is initially 0 an both
  the master and every worker:
</p>
</li>
</ul></div>
<div class="listingblock">
<div class="content">
<pre>

<code>Thread_context::Thread_context()
   : N(CNUM_INVALID),
     thread(0),
     *job_number(0)*,
     job_name("no-job-name"),
     blocked(false)
{
}</code>

</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
As long as the <strong>Thread_context::job_number</strong> of the master is equal to the
  <strong>Thread_context::job_number</strong> number of a worker, that worker busy-waits
  until both numbers differ. The master also increments the static variable
  <strong>busy_worker_count</strong>:
</p>
</li>
</ul></div>
<div class="listingblock">
<div class="content">
<pre>

<code>   /// start parallel execution of work in a worker
   void PF_fork()
      {
        while (get_master().job_number == job_number)
              /* busy wait until the master has increased job_number */ ;
      }</code>

</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
When the master finds new work (e.g. after interpreting a scalar APL
  function) then it inserts that work into the proper <strong>Parallel_job_list&lt;&gt;</strong> of
  each worker and increments its own <strong>Thread_context::job_number</strong> (in
  <strong>Thread_context::M_fork()</strong>). This causes all workers to begin their share of
  the work:
</p>
</li>
</ul></div>
<div class="listingblock">
<div class="content">
<pre>

<code>   /// start parallel execution of work at the master
   static void M_fork(const char * jname)
      {
        get_master().job_name = jname;
        atomic_add(busy_worker_count, active_core_count - 1);
        ++get_master().job_number;
      }</code>

</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
The workers perform their work and, after finishing it, increment their
  <strong>Thread_context::job_number</strong> and decrement <strong>busy_worker_count</strong>.again:
</p>
</li>
</ul></div>
<div class="listingblock">
<div class="content">
<pre>

<code>   /// end parallel execution of work in a worker
   void PF_join()
      {
        atomic_add(busy_worker_count, -1);   // we are ready
        ++job_number;            // we reached master job_number

        // wait until all workers finished or new job from master
        while (atomic_read(busy_worker_count) != 0 &amp;&amp;
               get_master().job_number == job_number)
              /* busy wait */ ;
      }</code>

</pre>
</div></div>
<div class="imageblock">
<div class="content">
<img src="./APL1.png" alt="APL1" />
</div>
</div>
<div class="paragraph"><p>The synchronization scheme above was designed such that as little interaction
between threads is needed and heavier constructs like semaphores could be
avoided.</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_notation">Notation</h2>
<div class="sectionbody">
<div class="paragraph"><p>In the context of parallel execution, the prefix <strong>M_</strong> designates functions
that are only called from the master thread, while the prefix <strong>PF_</strong> (for pool
function) designates functions that are called from a worker thread.</p></div>
<div class="paragraph"><p>Master functions only exist in class <strong>Thread_context</strong>, while pool functions
exist in classes <strong>Thread_context</strong>, <strong>ScalarFunction</strong>, <strong>Bif_OPER2_INNER</strong>, and
<strong>Bif_OPER2_OUTER</strong>. Note that the master thread itself acts like a worker
thread after returning from <strong>M_fork()</strong> and before calling <strong>M_join()</strong>.</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_benchmarking_of_the_parallel_execution">Benchmarking of the Parallel Execution</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_the_theory_8230">The Theory &#8230;</h3>
<div class="paragraph"><p>If a scalar APL function, is computed on a single core, then the time (most
conveniently expressed in terms of CPU cycles) to compute it for an APL array
with a ravel of length N is:</p></div>
<div class="paragraph"><p>T<sub>seq</sub>(N) = ⍺<sub>seq</sub> + β<sub>seq</sub> × N.</p></div>
<div class="paragraph"><p>In theory, the parallel computation of the same function on a number of cores
requires time:</p></div>
<div class="paragraph"><p>T<sub>par</sub>(N) = ⍺<sub>par</sub> + β<sub>par</sub> × N.</p></div>
<div class="paragraph"><p>The terms ⍺<sub>seq</sub> and ⍺<sub>par</sub> are the start-up times for the computation, while
the terms β<sub>seq</sub> and β<sub>par</sub> are the per-item times for the computation.</p></div>
<div class="paragraph"><p>Under normal circumstance one has:</p></div>
<div class="ulist"><ul>
<li>
<p>
⍺<sub>seq</sub> ≤  ⍺<sub>par</sub>
</p>
</li>
<li>
<p>
β<sub>seq</sub> ≥ β<sub>par</sub>
</p>
</li>
</ul></div>
<div class="paragraph"><p>Under ideal circumstances one even has</p></div>
<div class="paragraph"><p>β<sub>par</sub> = β<sub>seq</sub> ÷ C,  or: β<sub>seq</sub> ÷ β<sub>par</sub> = C.</p></div>
<div class="paragraph"><p>where C is the number of cores involved. The quotient <strong>β<sub>seq</sub> ÷ β<sub>par</sub></strong>  is
commonly known as the <strong>speed-up</strong> of the parallel execution.  The difference ⍺<sub>par</sub> - ⍺<sub>seq</sub> is primarily caused by functions like M_fork(), PF_fork(),
M_join() and PF_join() above, but also by the overhead caused by the
joblist mechanism that is required to efficiently parallelize scalar
operation on nested APL values.</p></div>
<div class="paragraph"><p>The equations above can be used to compute a break-even length N<sub>BE</sub> so
that:</p></div>
<div class="ulist"><ul>
<li>
<p>
T<sub>seq</sub>(N) &lt; T<sub>par</sub>(N) for N &lt; N<sub>BE</sub>
</p>
</li>
<li>
<p>
T<sub>seq</sub>(N) &gt; T<sub>par</sub>(N) for N &gt; N<sub>BE</sub>.
</p>
</li>
</ul></div>
<div class="paragraph"><p>That simply means that the computation for arrays with a short ravel (i.e. of
less than N<sub>BE</sub> items) it is faster to compute sequentially, while for longer
ravels it is faster to compute in parallel.</p></div>
<div class="paragraph"><p>The above formulae are easier to interpret if one plots the execution times
(on the Y axis) vs. the vector length (on the X axis). For example, if</p></div>
<div class="ulist"><ul>
<li>
<p>
⍺<sub>seq</sub> = 10, ⍺<sub>par</sub> = 10, i.e. T<sub>seq</sub>(N) = 10 + 10×N (green plot line)
</p>
</li>
<li>
<p>
β<sub>seq</sub> = 30, β<sub>par</sub> = 5, i.e. T<sub>par</sub>(N) = 30 + 5     (red plot line)
</p>
</li>
</ul></div>
<div class="paragraph"><p>then the theory predicts the following execution times:</p></div>
<div class="imageblock">
<div class="content">
<img src="./APL2.png" alt="APL2" />
</div>
</div>
<div class="paragraph"><p>As one can see, the intersection of the Y-axis (i.e. N=0) and the plot line
T<sub>seq</sub>(N) resp. T<sub>par</sub>(N) is the start-up time time ⍺<sub>seq</sub> resp. ⍺<sub>par</sub>.
The break-even length in this example is the intersection of the two plot
lines at N=4.</p></div>
</div>
<div class="sect2">
<h3 id="_8230_and_the_practice">&#8230; and the Practice</h3>
<div class="paragraph"><p>As <strong>Benjamin Brewster</strong> stated in 1882: <em>In theory there is no difference
between theory and practice, while in practice there is</em>.</p></div>
<div class="paragraph"><p>This statement is particularly true for benchmarking. Until about 1990, given
some piece of assembler code, it was feasible (and was actually done) to
compute the number of CPU cycles that the execution of that code would take.</p></div>
<div class="paragraph"><p>Since then a number of optimizations, both in hardware and in software, have
made it practically impossible to predict the execution time of a given code.
Even worse, these days the same code, executed again and again, typically
results in rather different cycle counts for each execution pass. Even if
"no" other processes execute on the same CPU on which a benchmark measurement
is performed (where "no other process" means not counting the typically 250 or
so operating system processes that are sitting idle on the CPU) the results
can differ substantially between different measurements of the same code.</p></div>
<div class="paragraph"><p>As to the practice, lets discuss the results of a benchmark:</p></div>
<div class="imageblock">
<div class="content">
<img src="./APL3.png" alt="APL3" />
</div>
</div>
<div class="paragraph"><p>This benchmark measured the time to compute Z←¯6 ○ MixIRC for different vector
lengths, ranging from N=200 to N=4000. MixIRC is a random mix of integer,
real and complex arguments of ¯6○ aka. <strong>arccosh</strong>. The benchmark worked well in
the sense that the measured numbers of CPU cycles were very much in line with
the theory. The thick lines are those that have the smallest squared
differences from the measurement points (the line that best matches the
measurement points).</p></div>
<div class="paragraph"><p>To be on the safe side, lets repeat <strong>the same</strong> benchmark:</p></div>
<div class="imageblock">
<div class="content">
<img src="./APL4.png" alt="APL4" />
</div>
</div>
<div class="paragraph"><p>This one went less well. One difference to the previous one is that the
deviations of the measurement points are considerably larger than in the
previous run. If one runs the benchmark many times, then it looks like the
deviations in the sequential execution are larger than in the parallel
execution. More importantly, the sequential start-up time ⍺<sub>seq</sub> is now
larger that the parallel start-up time ⍺<sub>par</sub>.</p></div>
<div class="paragraph"><p>These two examples are only meant to highlight some the problems that may occur
if one tries to determine the parameters ⍺ and β. The following is a summary
of findings after having performed many such measurements with GNU APL and
different core counts, vector lengths, and primitive functions:</p></div>
<div class="ulist"><ul>
<li>
<p>
every measurement needs to be visualized (plotted) in order to rule out too
  many or too large outliers.
</p>
</li>
<li>
<p>
for determining the start-up costs ⍺<sub>seq</sub> and ⍺<sub>par</sub> it seems to be better
  to use fewer vector lengths and also shorter vectors.
</p>
</li>
<li>
<p>
for determining the per-item costs β<sub>seq</sub> and β<sub>par</sub> it is better to
  use longer vectors.
</p>
</li>
<li>
<p>
scalar functions with a low β (like A+B) tend to give more obscure results
  (and lower speed-ups) than scalar functions with a higher β. This is
  primarily caused by the fact that all cores share the same interface to the
  (shared) main memory of the machine.
</p>
</li>
<li>
<p>
The speed-up of additional virtual cores (compared to physical ones) seems
  to be rather low. That is, for example, the speedup of 12 virtual cores (on
  a hyper-threaded CPU with 6 physical cores) is only marginally higher than on
  6 physical cores. GNU APL addresses this fact by distributing the load over
  the physical cores before placing hyper-threads on the physical cores.
</p>
</li>
</ul></div>
</div>
<div class="sect2">
<h3 id="_the_benchmark_workspace_scalar2_apl">The Benchmark Workspace Scalar2.apl</h3>
<div class="paragraph"><p>The workspace <strong>workspaces/Scalar2.apl</strong> can be used to measure the execution
times of scalar functions. GNU APL provides a number of internal performance
counters. These counters need to be enabled with
<strong>PERFORMANCE_COUNTERS_WANTED=yes</strong> in <strong>./configure</strong>, and the CPU must have a
cycle counter and an instruction to read it (currently only Intel CPUs can use
this feature). The cycle counter of the CPU is read before and after the
computation of a scalar function, and the difference can be read in APL via
<strong>⎕FIO[200]</strong> and <strong>⎕FIO[201]</strong>. Measuring execution times this way is far more
precise than old-fashioned measurements using ⎕TS at APL level.</p></div>
<div class="paragraph"><p>Scalar2.apl is most conveniently called from the command line, and what is
being measured can be controlled via command line arguments. For example:</p></div>
<div class="listingblock">
<div class="content">
<pre>

<code>apl -f workspaces/Scalar2.apl -- -c 3,6 -d 200×⍳20</code>

</pre>
</div></div>
<div class="paragraph"><p>The following command line options are supported by <strong>Scalar2.apl</strong>:</p></div>
<div class="tableblock">
<table rules="all"
width="75%"
frame="border"
cellspacing="0" cellpadding="4">
<caption class="title">Table 1. Table Scalar2.apl command line options (after --)</caption>
<col width="25%" />
<col width="41%" />
<col width="16%" />
<col width="16%" />
<thead>
<tr>
<th align="left" valign="top">Option           </th>
<th align="left" valign="top">Effect                         </th>
<th align="center" valign="top">Example  </th>
<th align="center" valign="top">Default</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p class="table">-c core-counts</p></td>
<td align="left" valign="top"><p class="table">set the number of cores</p></td>
<td align="center" valign="top"><p class="table">-c 2,3</p></td>
<td align="center" valign="top"><p class="table">2</p></td>
</tr>
<tr>
<td align="left" valign="top"><p class="table">-d vector-lengths</p></td>
<td align="left" valign="top"><p class="table">set the vector lengths (N-axis)</p></td>
<td align="center" valign="top"><p class="table">-d 200×⍳2</p></td>
<td align="center" valign="top"><p class="table">⍳20</p></td>
</tr>
<tr>
<td align="left" valign="top"><p class="table">-f function</p></td>
<td align="left" valign="top"><p class="table">select the function to measure</p></td>
<td align="center" valign="top"><p class="table">-f 20</p></td>
<td align="center" valign="top"><p class="table">39</p></td>
</tr>
</tbody>
</table>
</div>
<div class="paragraph"><p>For every core count, <strong>Scalar2.apl</strong> displays a separate plot window with the
measurement results for sequential execution and for the parallel execution
with the given core count.</p></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_recursive_parallelization">Recursive Parallelization</h2>
<div class="sectionbody">
<div class="paragraph"><p>The purpose of the joblist mentioned above is as follows. Consider the
APL expression below, computed in parallel on 4 cores:</p></div>
<div class="listingblock">
<div class="content">
<pre>

<code>Z←1 2 (⍳1000) 4 + 1 (20 21 22) 3 4</code>

</pre>
</div></div>
<div class="paragraph"><p>The 4 ravel elements of the left and right arguments of dyadic + are stored in
4 consecutive Cells, which are distributed in a round-robin fashion over the
cores. That is:</p></div>
<div class="listingblock">
<div class="content">
<pre>

<code>Core #1 computes: 1 + 1              (1 addition)
Core #2 computes: 2 + 20 21 22       (3 additions)
Core #3 computes: (⍳1000) + 3        (1000 additions)
Core #4 computes: 4 + 4              (1 addition)</code>

</pre>
</div></div>
<div class="paragraph"><p>Therefore cores #1 and #4 computes one sum, core #2 computes 3 sums, and
core #3 compute 1000 sums. This is obviously not optimal since cores #1, #2,
and #3 are most of the time idle, waiting for core #3 to finish.</p></div>
<div class="paragraph"><p>To avoid this case, GNU APL parallelizes scalar functions recursively with the
following algorithm.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
the interpreter starts with an empty joblist.
</p>
</li>
<li>
<p>
when the interpreter evaluates a scalar function, then it puts a new job
   into the joblist  The job describes the relevant parameters (essentially
   the  scalar function to be computed and the address(es) of its argument(s).
</p>
</li>
<li>
<p>
LOOP: while the joblist is not empty:
</p>
<div class="olist loweralpha"><ol class="loweralpha">
<li>
<p>
remove the first job from the list
</p>
</li>
<li>
<p>
perform the computation defined in the job in parallel
</p>
</li>
<li>
<p>
if a core comes across a nested ravel item, then:
</p>
<div class="ulist"><ul>
<li>
<p>
if the item (and hence the result) is small: compute it immediately
</p>
</li>
<li>
<p>
if the item is large: create a new APL value whose ravel is un-initialized
  (this operation takes constant time) and add a new entry into the joblist
  (for computing the ravel of the nested result later on).
</p>
</li>
</ul></div>
</li>
</ol></div>
</li>
</ol></div>
<div class="paragraph"><p>For performance reasons, there are actually two such joblists:
<strong>Thread_context::joblist_B</strong> for monadic scalar functions, and
<strong>Thread_context::joblist_AB</strong> for dyadic scalar functions (and
inner and outer products of them).</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_setting_thresholds">Setting Thresholds</h2>
<div class="sectionbody">
<div class="paragraph"><p>One purpose of the benchmarking is to find the break-even lengths for
scalar functions. After that length was found, one can inform the APL
interpreter about the break-even lengths. This is done via a configuration
file, normally <strong>/usr/local/etc/gnu-apl.d/parallel_thresholds</strong>.</p></div>
<div class="paragraph"><p>This file is installed by <em>make install</em>, but the values in the file
are usually not optimal. One can, however, enter better values manually.
Consider a few non-empty lines in the file:</p></div>
<div class="listingblock">
<div class="content">
<pre>

<code>perfo_1(F12_PLUS,      _B,   "+ B",    8888888888888888888ULL)
perfo_1(F12_POWER,     _B,   "⋆ B",    12                    )
perfo_2(F12_TIMES,     _AB,  "A × B",  33                    )</code>

</pre>
</div></div>
<div class="paragraph"><p>The first line above sets the break-even point of <strong>monadic +</strong> to
8888888888888888888ULL, which is a value so large that parallel execution will
never happen for monadic +.</p></div>
<div class="paragraph"><p>The second line sets the break-even point of <strong>monadic *</strong> to 12. Arrays (of any
rank) with fewer than 12 ravel items will be computed sequentially, but longer
arrays in parallel.</p></div>
<div class="paragraph"><p>The third line sets the break-even point of <strong>dyadic ×</strong> to 33. Arrays (of any
rank) with fewer than 33 ravel items will be computed sequentially, nut longer
arrays in parallel.</p></div>
<div class="paragraph"><p>In general, the fewer cycles a function needs, the higher should the threshold
be set.</p></div>
</div>
</div>
</div>
<div id="footnotes"><hr /></div>
<div id="footer">
<div id="footer-text">
Last updated
 2020-07-25 13:02:37 CEST
</div>
</div>
</body>
</html>
